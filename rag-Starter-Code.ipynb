{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fc17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/pymilvus/client/__init__.py:6: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/ragas/metrics/__init__.py:1: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from ragas.metrics._answer_correctness import AnswerCorrectness, answer_correctness\n",
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/ragas/metrics/__init__.py:4: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from ragas.metrics._context_entities_recall import (\n"
     ]
    }
   ],
   "source": [
    "# Load all required Libraries\n",
    "import sys, subprocess\n",
    "try:\n",
    "    import sentence_transformers  # noqa: F401\n",
    "except Exception:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", \"assignment2-rag/requirements.txt\"])  # installs deps if missing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType\n",
    "\n",
    "import evaluate as hf_evaluate\n",
    "from ragas import evaluate as ragas_evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2a7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: P\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, requests, json, time\n",
    "\n",
    "API_KEY = \"SECRET_KEY\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "client_openai = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "try:\n",
    "    r = client_openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\":\"user\",\"content\":\"ping\"}],\n",
    "        max_tokens=1,\n",
    "        temperature=0\n",
    "    )\n",
    "    print(\"OK:\", r.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(\"ERROR:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ab245",
   "metadata": {},
   "source": [
    "# Read Passages from the Datasets and Drop rows if they are NA or empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0e11a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uruguay (official full name in  ; pron.  , Eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is bordered by Brazil to the north, by Arge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Montevideo was founded by the Spanish in the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The economy is largely based in agriculture (m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to Transparency International, Urugu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              passage\n",
       "id                                                   \n",
       "0   Uruguay (official full name in  ; pron.  , Eas...\n",
       "1   It is bordered by Brazil to the north, by Arge...\n",
       "2   Montevideo was founded by the Spanish in the e...\n",
       "3   The economy is largely based in agriculture (m...\n",
       "4   According to Transparency International, Urugu..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/passages.parquet/part.0.parquet\")\n",
    "\n",
    "# drop rows if they are NA or empty\n",
    "passages = passages.dropna(subset=[\"passage\"])\n",
    "passages = passages[passages[\"passage\"].astype(str).str.strip().ne(\"\")]\n",
    "\n",
    "print(passages.shape)\n",
    "passages_reset = passages.reset_index()\n",
    "passages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45249cd2",
   "metadata": {},
   "source": [
    "# Do EDA on the passage dataset\n",
    "- You can try to find the maximum and minimum length of the passages before indexing (just a direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa0d0a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_passages': 3200, 'min_len': 1, 'max_len': 2515, 'avg_len': 389.848125, 'median_len': 299.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['In some beetles, the ability to fly has been lost. These include the ground beetles (family Carabidae) and some \"true weevils\" (family Curculionidae), but also some desert and cave-dwelling species of other families. Many of these species have the two elytra fused together, forming a solid shield over the abdomen. In a few families, both the ability to fly and the elytra have been lost, with the best known example being the glow-worms of the family Phengodidae, in which the females are larviform throughout their lives.',\n",
       " 'The name \"Qatar\" may derive from the same Arabic root as qatura which means \"to exude.\"  The word Qatura traces to the Arabic qatran meaning \"tar\" or \"resin\", which relates to the country\\'s rich resources in petroleum and natural gas.  Adrian Room, Placenames of the World (1997) McFarland and Company.',\n",
       " \"President Woodrow Wilson articulated what became known as the Fourteen Points before Congress on January 8, 1918.  The Points were the only war aims clearly expressed by any belligerent nation and thus became the basis for the Treaty of Versailles following World War I.  The speech was highly idealistic, translating Wilson's progressive domestic policy of democracy, self-determination, open agreements, and free trade into the international realm.  It also made several suggestions for specific disputes in Europe on the recommendation of Wilson's foreign policy advisor, Colonel Edward M. House, and his team of 150 advisors known as â\\x80\\x9cThe Inquiry.â\\x80\\x9d  The points were:\",\n",
       " '|}',\n",
       " '* 3. If the plane is straight across, the section cut out will be a circle.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code for EDA\n",
    "passages_series = passages[\"passage\"].astype(str)\n",
    "lengths = passages_series.str.len()\n",
    "print({\n",
    "    \"num_passages\": len(passages_series),\n",
    "    \"min_len\": int(lengths.min()),\n",
    "    \"max_len\": int(lengths.max()),\n",
    "    \"avg_len\": float(lengths.mean()),\n",
    "    \"median_len\": float(lengths.median()),\n",
    "})\n",
    "passages_series.sample(5, random_state=42).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b32f3",
   "metadata": {},
   "source": [
    "# Tokenize Text and Generate Embeddings using Sentence Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f39adefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Batches: 100%|██████████| 50/50 [00:11<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"  # 384-dim\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# Encode Text\n",
    "passages_reset = passages.reset_index()  # ensure 'id' is a column\n",
    "passage_texts = passages_reset[\"passage\"].astype(str).tolist()\n",
    "embeddings = embedding_model.encode(\n",
    "    passage_texts,\n",
    "    batch_size=64,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    ")\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354e711",
   "metadata": {},
   "source": [
    "# Create Milvus Client and Insert your Embeddings to your DB\n",
    "- Make sure you define a schema for your collection (Points will be deducted if you fail to define a proper schema with ids, passage text, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64ccfdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define every column of your schema\n",
    "\n",
    "# Infer embedding dimension from computed embeddings\n",
    "embedding_dim = int(embeddings.shape[1])\n",
    "\n",
    "id_ = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False)\n",
    "passage = FieldSchema(name=\"passage\", dtype=DataType.VARCHAR, max_length=8192)\n",
    "embedding = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13b4c62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = CollectionSchema(fields=[id_, passage, embedding], description=\"RAG Mini Wikipedia collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ed3c24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created: rag_mini\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "DB_PATH = \"rag_wikipedia_mini_v3.db\"  # new file to avoid lock\n",
    "client = MilvusClient(DB_PATH)\n",
    "\n",
    "# Create the Collection with Collection Name = \"rag_mini\". Make sure you define the schema variable while creating the collection\n",
    "try:\n",
    "    if client.has_collection(\"rag_mini\"):\n",
    "        client.drop_collection(\"rag_mini\")\n",
    "except Exception as e:\n",
    "    print(\"Drop existing rag_mini failed:\", e)\n",
    "\n",
    "try:\n",
    "    client.create_collection(\n",
    "        collection_name=\"rag_mini\",\n",
    "        schema=schema,\n",
    "        shard_num=1,\n",
    "    )\n",
    "    print(\"Collection created: rag_mini\")\n",
    "except Exception as e:\n",
    "    print(f\"Create collection result: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b067a",
   "metadata": {},
   "source": [
    "**Convert your Pandas Dataframe to a list of dictionaries**\n",
    "- The Dictionary at least have 3 keys [id, passage, embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b60520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200 rows ready for insert\n"
     ]
    }
   ],
   "source": [
    "# Convert Pandas DataFrame + embeddings to Milvus row dicts\n",
    "ids = passages_reset[\"id\"].astype(int).tolist()\n",
    "rag_data = [\n",
    "    {\n",
    "        \"id\": int(idx),\n",
    "        \"passage\": str(text),\n",
    "        \"embedding\": emb.astype(float).tolist(),\n",
    "    }\n",
    "    for idx, text, emb in zip(ids, passage_texts, embeddings)\n",
    "]\n",
    "print(len(rag_data), \"rows ready for insert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba91d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted: 3200\n"
     ]
    }
   ],
   "source": [
    "# Code to insert the data to your DB\n",
    "try:\n",
    "    res = client.insert(collection_name=\"rag_mini\", data=rag_data)\n",
    "    print(\"Inserted:\", res.get(\"insert_count\", res))\n",
    "except Exception as e:\n",
    "    print(f\"Insert result: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bba2a1a",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "- Do a Sanity Check on your database \n",
    "\n",
    "**Do not delete the below line during your submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e73b817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity count: 3200\n",
      "Collection schema: {'collection_name': 'rag_mini', 'auto_id': False, 'num_shards': 0, 'description': 'RAG Mini Wikipedia collection', 'fields': [{'field_id': 100, 'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'params': {}, 'is_primary': True}, {'field_id': 101, 'name': 'passage', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 8192}}, {'field_id': 102, 'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}], 'aliases': [], 'collection_id': 0, 'consistency_level': 0, 'properties': {}, 'num_partitions': 0, 'enable_dynamic_field': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"Entity count:\", client.get_collection_stats(\"rag_mini\")[\"row_count\"])\n",
    "print(\"Collection schema:\", client.describe_collection(\"rag_mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87920ab",
   "metadata": {},
   "source": [
    "# Steps to Fetch Results\n",
    "- Read the Question Dataset\n",
    "- Clean the Question Dataset if necessary (Drop Questions with NaN etc.)\n",
    "- Convert Each Query to a Vector Embedding (Use the same embedding model you used to embed your document)\n",
    "- Try for a Single Question First\n",
    "- Load Collection into Memory after creating Index for Search on your embedding field (This is an essential step before you can search in your db)\n",
    "- Search and Fetch Top N Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da659821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(918, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did Lincoln sign the National Banking Act of 1...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did his mother die of pneumonia?</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How many long was Lincoln's formal education?</td>\n",
       "      <td>18 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>When did Lincoln begin his political career?</td>\n",
       "      <td>1832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question     answer\n",
       "id                                                              \n",
       "0   Was Abraham Lincoln the sixteenth President of...        yes\n",
       "2   Did Lincoln sign the National Banking Act of 1...        yes\n",
       "4                    Did his mother die of pneumonia?         no\n",
       "6       How many long was Lincoln's formal education?  18 months\n",
       "8        When did Lincoln begin his political career?       1832"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "queries = pd.read_parquet(\"hf://datasets/rag-datasets/rag-mini-wikipedia/data/test.parquet/part.0.parquet\")\n",
    "\n",
    "queries = queries.dropna(subset=[\"question\"])\n",
    "queries = queries[queries[\"question\"].astype(str).str.strip().ne(\"\")]\n",
    "\n",
    "print(queries.shape)\n",
    "\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849c5762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n"
     ]
    }
   ],
   "source": [
    "query = queries.iloc[0][\"question\"]\n",
    "\n",
    "query_embedding = embedding_model.encode([str(query)], normalize_embeddings=True)\n",
    "\n",
    "print(query_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43c1383",
   "metadata": {},
   "source": [
    "#### Create Index on the embedding column on your DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22563d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created on embedding\n",
      "Collection loaded into memory\n"
     ]
    }
   ],
   "source": [
    "index_params = MilvusClient.prepare_index_params()\n",
    "\n",
    "# Add an index on the embedding field\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_type=\"AUTOINDEX\",  # or IVF_FLAT/HNSW if desired\n",
    "    metric_type=\"IP\",        # cosine works when normalized; use IP for speed\n",
    "    params={}\n",
    ")\n",
    "\n",
    "# Create the index\n",
    "try:\n",
    "    client.create_index(collection_name=\"rag_mini\", index_params=index_params)\n",
    "    print(\"Index created on embedding\")\n",
    "except Exception as e:\n",
    "    print(f\"Index creation result: {e}\")\n",
    "\n",
    "# Load collection into memory (required for search)\n",
    "try:\n",
    "    client.load_collection(collection_name=\"rag_mini\")\n",
    "    print(\"Collection loaded into memory\")\n",
    "except Exception as e:\n",
    "    print(f\"Load collection result: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d4583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build second collection with all-mpnet-base-v2\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# MPNET_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "# embedding_model_mpnet = SentenceTransformer(MPNET_MODEL_NAME)\n",
    "# mpnet_embeddings = embedding_model_mpnet.encode(\n",
    "#     passage_texts,\n",
    "#     batch_size=64,\n",
    "#     convert_to_numpy=True,\n",
    "#     show_progress_bar=True,\n",
    "#     normalize_embeddings=True,\n",
    "# )\n",
    "# embedding_dim_mpnet = int(mpnet_embeddings.shape[1])\n",
    "\n",
    "# id2 = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False)\n",
    "# passage2 = FieldSchema(name=\"passage\", dtype=DataType.VARCHAR, max_length=8192)\n",
    "# embedding2 = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim_mpnet)\n",
    "# schema_mpnet = CollectionSchema(fields=[id2, passage2, embedding2], description=\"RAG Mini Wikipedia mpnet\")\n",
    "\n",
    "# try:\n",
    "#     client.create_collection(collection_name=\"rag_mini_mpnet\", schema=schema_mpnet, shard_num=1)\n",
    "#     print(\"Collection created: rag_mini_mpnet\")\n",
    "# except Exception as e:\n",
    "#     print(\"Create collection (mpnet):\", e)\n",
    "\n",
    "# rag_data_mpnet = [\n",
    "#     {\"id\": int(idx), \"passage\": str(text), \"embedding\": emb.astype(float).tolist()}\n",
    "#     for idx, text, emb in zip(ids, passage_texts, mpnet_embeddings)\n",
    "# ]\n",
    "# res = client.insert(collection_name=\"rag_mini_mpnet\", data=rag_data_mpnet)\n",
    "# print(\"Inserted mpnet:\", res.get(\"insert_count\", res))\n",
    "\n",
    "# index_params2 = MilvusClient.prepare_index_params()\n",
    "# index_params2.add_index(field_name=\"embedding\", index_type=\"AUTOINDEX\", metric_type=\"IP\", params={})\n",
    "# try:\n",
    "#     client.create_index(collection_name=\"rag_mini_mpnet\", index_params=index_params2)\n",
    "#     client.load_collection(collection_name=\"rag_mini_mpnet\")\n",
    "#     print(\"rag_mini_mpnet loaded\")\n",
    "# except Exception as e:\n",
    "#     print(\"Index/load (mpnet):\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e60b217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Batches: 100%|██████████| 50/50 [00:51<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection created: rag_mini_mpnet\n",
      "Inserted mpnet: 3200\n",
      "rag_mini_mpnet loaded\n"
     ]
    }
   ],
   "source": [
    "# Build second collection with all-mpnet-base-v2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "MPNET_MODEL_NAME = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "embedding_model_mpnet = SentenceTransformer(MPNET_MODEL_NAME)\n",
    "mpnet_embeddings = embedding_model_mpnet.encode(\n",
    "    passage_texts,\n",
    "    batch_size=64,\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    ")\n",
    "embedding_dim_mpnet = int(mpnet_embeddings.shape[1])\n",
    "\n",
    "id2 = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=False)\n",
    "passage2 = FieldSchema(name=\"passage\", dtype=DataType.VARCHAR, max_length=8192)\n",
    "embedding2 = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim_mpnet)\n",
    "schema_mpnet = CollectionSchema(fields=[id2, passage2, embedding2], description=\"RAG Mini Wikipedia mpnet\")\n",
    "\n",
    "try:\n",
    "    if client.has_collection(\"rag_mini_mpnet\"):\n",
    "        client.drop_collection(\"rag_mini_mpnet\")\n",
    "except Exception as e:\n",
    "    print(\"Drop existing rag_mini_mpnet failed:\", e)\n",
    "\n",
    "try:\n",
    "    client.create_collection(collection_name=\"rag_mini_mpnet\", schema=schema_mpnet, shard_num=1)\n",
    "    print(\"Collection created: rag_mini_mpnet\")\n",
    "except Exception as e:\n",
    "    print(\"Create collection (mpnet):\", e)\n",
    "\n",
    "rag_data_mpnet = [\n",
    "    {\"id\": int(idx), \"passage\": str(text), \"embedding\": emb.astype(float).tolist()}\n",
    "    for idx, text, emb in zip(ids, passage_texts, mpnet_embeddings)\n",
    "]\n",
    "res = client.insert(collection_name=\"rag_mini_mpnet\", data=rag_data_mpnet)\n",
    "print(\"Inserted mpnet:\", res.get(\"insert_count\", res))\n",
    "\n",
    "index_params2 = MilvusClient.prepare_index_params()\n",
    "index_params2.add_index(field_name=\"embedding\", index_type=\"AUTOINDEX\", metric_type=\"IP\", params={})\n",
    "try:\n",
    "    client.create_index(collection_name=\"rag_mini_mpnet\", index_params=index_params2)\n",
    "    client.load_collection(collection_name=\"rag_mini_mpnet\")\n",
    "    print(\"rag_mini_mpnet loaded\")\n",
    "except Exception as e:\n",
    "    print(\"Index/load (mpnet):\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "664364e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [\"[{'id': 288, 'distance': 0.7095188498497009, 'entity': {}}, {'id': 278, 'distance': 0.5840359926223755, 'entity': {}}, {'id': 698, 'distance': 0.5568779110908508, 'entity': {}}, {'id': 2228, 'distance': 0.5566980838775635, 'entity': {}}, {'id': 319, 'distance': 0.5500738024711609, 'entity': {}}, {'id': 390, 'distance': 0.548395037651062, 'entity': {}}, {'id': 1813, 'distance': 0.5443781614303589, 'entity': {}}, {'id': 317, 'distance': 0.5384628176689148, 'entity': {}}, {'id': 392, 'distance': 0.538284182548523, 'entity': {}}, {'id': 289, 'distance': 0.530716061592102, 'entity': {}}]\"] , extra_info: {'cost': 0}\n",
      "Top IDs: [288, 278, 698, 2228, 319]\n"
     ]
    }
   ],
   "source": [
    "# Search the db with your query embedding\n",
    "search_res = client.search(\n",
    "    collection_name=\"rag_mini\",\n",
    "    data=query_embedding.tolist(),\n",
    "    anns_field=\"embedding\",\n",
    "    limit=10,\n",
    "    search_params={\"metric_type\": \"IP\"}\n",
    ")\n",
    "print(search_res)\n",
    "# Extract ids and distances for top-k\n",
    "hits = search_res[0]\n",
    "retrieved_ids = [hit[\"id\"] for hit in hits]\n",
    "retrieved_scores = [hit[\"distance\"] for hit in hits]\n",
    "print(\"Top IDs:\", retrieved_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe7a24",
   "metadata": {},
   "source": [
    "## Now get the Context \n",
    "- Initially use the first passage ONLY as your context\n",
    "- In Later Experiments, you must try at least 2 different passage selection strategies (Top 3 / Top 5 / Top 10) and pass to your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eea31d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Young Abraham Lincoln ...\n"
     ]
    }
   ],
   "source": [
    "# Use first retrieved passage as context\n",
    "first_id = int(retrieved_ids[0])\n",
    "context = passages_reset.loc[passages_reset[\"id\"] == first_id, \"passage\"].values[0]\n",
    "print(context[:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b68ab",
   "metadata": {},
   "source": [
    "**Develop your Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca4674fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Context: Young Abraham Lincoln: \n",
      " Question: Was Abraham Lincoln the sixteenth President of the United States? \n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\n",
    "\n",
    "prompt = f\"\"\"{system_prompt} \\n Context: {context}: \\n Question: {query} \"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7bb4e9",
   "metadata": {},
   "source": [
    "# RAG Response for a Single Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eadd108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yerouwang/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the LLM Model you want to use (small seq2seq for offline use)\n",
    "GEN_MODEL = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL)\n",
    "llm = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL)\n",
    "\n",
    "def generate_answer(prompt_text: str, max_new_tokens: int = 128) -> str:\n",
    "    inputs = tokenizer(\n",
    "        prompt_text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        output_ids = llm.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    return tokenizer.decode(output_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dff0c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: no\n"
     ]
    }
   ],
   "source": [
    "# Generate answer\n",
    "answer = generate_answer(prompt)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "# Decode and extract answer.\n",
    "# Already decoded above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9023b43c",
   "metadata": {},
   "source": [
    "# Generate Responses for all the Queries in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc262ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 181/918 [00:27<01:50,  6.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m retrieved_first_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m tqdm(clean_queries[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()):\n\u001b[0;32m---> 10\u001b[0m     q_emb \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     sres \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39msearch(\n\u001b[1;32m     12\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrag_mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m         data\u001b[38;5;241m=\u001b[39mq_emb\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m         search_params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIP\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     top_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sres[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sres) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sres[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sentence_transformers/SentenceTransformer.py:371\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    368\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 371\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m truncate_embeddings(\n\u001b[1;32m    373\u001b[0m         out_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\n\u001b[1;32m    374\u001b[0m     )\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/container.py:244\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sentence_transformers/models/Transformer.py:98\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     96\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 98\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py:1077\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1077\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1086\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/bert/modeling_bert.py:210\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    207\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[1;32m    213\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/sparse.py:192\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:2546\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2542\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2545\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Batch inference over queries using top-1 context\n",
    "clean_queries = queries.dropna(subset=[\"question\"]).copy()\n",
    "clean_queries[\"question\"] = clean_queries[\"question\"].astype(str)\n",
    "\n",
    "pred_answers = []\n",
    "retrieved_first_ids = []\n",
    "for q in tqdm(clean_queries[\"question\"].tolist()):\n",
    "    q_emb = embedding_model.encode([q], normalize_embeddings=True)\n",
    "    sres = client.search(\n",
    "        collection_name=\"rag_mini\",\n",
    "        data=q_emb.tolist(),\n",
    "        anns_field=\"embedding\",\n",
    "        limit=10,\n",
    "        search_params={\"metric_type\": \"IP\"}\n",
    "    )\n",
    "    top_id = int(sres[0][0][\"id\"]) if len(sres) > 0 and len(sres[0]) > 0 else -1\n",
    "    retrieved_first_ids.append(top_id)\n",
    "    ctx = passages_reset.loc[passages_reset[\"id\"] == top_id, \"passage\"].values\n",
    "    ctx_text = ctx[0] if len(ctx) > 0 else \"\"\n",
    "    sys_prompt = \"You are a helpful assistant. Answer concisely using the provided context. If unknown, say you don't know.\"\n",
    "    prompt_i = f\"{sys_prompt}\\nContext: {ctx_text}\\nQuestion: {q}\"\n",
    "    pred = generate_answer(prompt_i)\n",
    "    pred_answers.append(pred)\n",
    "\n",
    "batch_df = clean_queries[[\"question\", \"answer\"]].copy()\n",
    "batch_df[\"pred_answer\"] = pred_answers\n",
    "batch_df[\"retrieved_id\"] = retrieved_first_ids\n",
    "batch_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1b77e",
   "metadata": {},
   "source": [
    "# Finding out the Basic QA Metrics (F1 score, EM score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Simple prompting strategies comparison (top-1, same retriever)\n",
    "# prompts = [\n",
    "#     \"Answer concisely using only the context. If unknown, say you don't know.\\nContext: {ctx}\\nQuestion: {q}\",\n",
    "#     \"You are a strict QA system. Use only the context; if missing, say 'I don't know'.\\nContext: {ctx}\\nQuestion: {q}\",\n",
    "#     \"Provide a short, direct answer based on the context only.\\nContext: {ctx}\\nQuestion: {q}\",\n",
    "# ]\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# tmp_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# def eval_prompt(template):\n",
    "#     preds = []\n",
    "#     refs = clean_queries[\"answer\"].astype(str).tolist()\n",
    "#     for q in clean_queries[\"question\"].astype(str).tolist():\n",
    "#         q_emb = tmp_model.encode([q], normalize_embeddings=True)\n",
    "#         sres = client.search(collection_name=\"rag_mini\", data=q_emb.tolist(), anns_field=\"embedding\", limit=1, search_params={\"metric_type\": \"IP\"})\n",
    "#         pid = int(sres[0][0][\"id\"])\n",
    "#         ctx = passages_reset.loc[passages_reset[\"id\"]==pid,\"passage\"].values[0]\n",
    "#         pred = generate_answer(template.format(ctx=ctx, q=q))\n",
    "#         preds.append(pred)\n",
    "#     em_ = sum(exact_match_score(p, r) for p, r in zip(preds, refs)) / len(refs) * 100.0\n",
    "#     f1_ = sum(f1_score(p, r) for p, r in zip(preds, refs)) / len(refs) * 100.0\n",
    "#     return em_, f1_\n",
    "\n",
    "# prompt_scores = [eval_prompt(t) for t in prompts]\n",
    "# print(prompt_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02f1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 41.50326797385621, 'f1': 48.547767028825}\n"
     ]
    }
   ],
   "source": [
    "# Offline SQuAD-style EM/F1\n",
    "\n",
    "import re, string, json\n",
    "\n",
    "def normalize_answer(s: str) -> str:\n",
    "    def remove_articles(text): return re.sub(r\"\\b(a|an|the)\\b\", \" \", text, flags=re.IGNORECASE)\n",
    "    def remove_punc(text): return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    def white_space_fix(text): return \" \".join(text.split())\n",
    "    return white_space_fix(remove_articles(remove_punc(s.lower())))\n",
    "\n",
    "def exact_match_score(pred: str, truth: str) -> int:\n",
    "    return int(normalize_answer(pred) == normalize_answer(truth))\n",
    "\n",
    "def f1_score(pred: str, truth: str) -> float:\n",
    "    p = normalize_answer(pred).split(); t = normalize_answer(truth).split()\n",
    "    if not p and not t: return 1.0\n",
    "    if not p or not t: return 0.0\n",
    "    common = {}\n",
    "    for tok in set(p):\n",
    "        common[tok] = min(p.count(tok), t.count(tok))\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0: return 0.0\n",
    "    precision = num_same / len(p); recall = num_same / len(t)\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "preds = batch_df[\"pred_answer\"].astype(str).tolist()\n",
    "refs = batch_df[\"answer\"].astype(str).tolist()\n",
    "\n",
    "em = sum(exact_match_score(p, r) for p, r in zip(preds, refs)) / len(refs) * 100.0\n",
    "f1 = sum(f1_score(p, r) for p, r in zip(preds, refs)) / len(refs) * 100.0\n",
    "\n",
    "print({\"exact_match\": em, \"f1\": f1})\n",
    "\n",
    "with open(\"naive_results.json\", \"w\") as f:\n",
    "    json.dump({\"em\": em, \"f1\": f1}, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072ac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'em_mean': 41.50326797385621, 'em_ci': (0.38344226579520696, 0.44937363834422656), 'f1_mean': 48.54776702882495, 'f1_ci': (0.45592722971165917, 0.5147832400573178)}\n",
      "error_type\n",
      "other             506\n",
      "correct           309\n",
      "yn_mismatch        77\n",
      "number_missing     26\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred_answer</th>\n",
       "      <th>error_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Was Abraham Lincoln the sixteenth President of...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yn_mismatch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What did The Legal Tender Act of 1862 establish?</td>\n",
       "      <td>the United States Note, the first paper curren...</td>\n",
       "      <td>United States Note</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Who suggested Lincoln grow a beard?</td>\n",
       "      <td>11-year-old Grace Bedell</td>\n",
       "      <td>Grace Bedell</td>\n",
       "      <td>number_missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>When did the Gettysburg address argue that Ame...</td>\n",
       "      <td>1776</td>\n",
       "      <td>1789</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Which county was Lincoln born in?</td>\n",
       "      <td>Hardin County</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>When did Lincoln first serve as President?</td>\n",
       "      <td>March 4, 1861</td>\n",
       "      <td>1861</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Who assassinated Lincoln?</td>\n",
       "      <td>John Wilkes Booth</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Who was the general in charge at the Battle of...</td>\n",
       "      <td>General McClellan</td>\n",
       "      <td>Ambrose Burnside</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Why did Lincoln issue the Emancipation Proclam...</td>\n",
       "      <td>To free slaves</td>\n",
       "      <td>freed slaves in territories not under Union co...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Was Lincoln chosen as a presidential candidate...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lincoln was eventually chosen as the Republica...</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "id                                                      \n",
       "0   Was Abraham Lincoln the sixteenth President of...   \n",
       "10   What did The Legal Tender Act of 1862 establish?   \n",
       "12                Who suggested Lincoln grow a beard?   \n",
       "14  When did the Gettysburg address argue that Ame...   \n",
       "24                  Which county was Lincoln born in?   \n",
       "26         When did Lincoln first serve as President?   \n",
       "28                          Who assassinated Lincoln?   \n",
       "32  Who was the general in charge at the Battle of...   \n",
       "34  Why did Lincoln issue the Emancipation Proclam...   \n",
       "41  Was Lincoln chosen as a presidential candidate...   \n",
       "\n",
       "                                               answer  \\\n",
       "id                                                      \n",
       "0                                                 yes   \n",
       "10  the United States Note, the first paper curren...   \n",
       "12                           11-year-old Grace Bedell   \n",
       "14                                               1776   \n",
       "24                                      Hardin County   \n",
       "26                                      March 4, 1861   \n",
       "28                                  John Wilkes Booth   \n",
       "32                                  General McClellan   \n",
       "34                                    To free slaves    \n",
       "41                                                Yes   \n",
       "\n",
       "                                          pred_answer      error_type  \n",
       "id                                                                     \n",
       "0                                                  no     yn_mismatch  \n",
       "10                                 United States Note           other  \n",
       "12                                       Grace Bedell  number_missing  \n",
       "14                                               1789           other  \n",
       "24                                        Springfield           other  \n",
       "26                                               1861           other  \n",
       "28                                    Abraham Lincoln           other  \n",
       "32                                   Ambrose Burnside           other  \n",
       "34  freed slaves in territories not under Union co...           other  \n",
       "41  Lincoln was eventually chosen as the Republica...           other  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% CI + failure analysis for naive batch_df (repeat for enhanced if needed)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def bootstrap_ci(vals, n_boot=500, alpha=0.05, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    vals = np.array(vals, dtype=float)\n",
    "    boots = [np.mean(vals[rng.integers(0, len(vals), len(vals))]) for _ in range(n_boot)]\n",
    "    lo = float(np.percentile(boots, 100*alpha/2))\n",
    "    hi = float(np.percentile(boots, 100*(1-alpha/2)))\n",
    "    return lo, hi\n",
    "\n",
    "per_em = [int(exact_match_score(p, r)) for p, r in zip(batch_df[\"pred_answer\"], batch_df[\"answer\"])]\n",
    "per_f1 = [f1_score(p, r) for p, r in zip(batch_df[\"pred_answer\"], batch_df[\"answer\"])]\n",
    "em_ci = bootstrap_ci(per_em)\n",
    "f1_ci = bootstrap_ci(per_f1)\n",
    "print({\"em_mean\": float(np.mean(per_em))*100, \"em_ci\": em_ci,\n",
    "       \"f1_mean\": float(np.mean(per_f1))*100, \"f1_ci\": f1_ci})\n",
    "\n",
    "def error_type(pred, ref):\n",
    "    p, r = str(pred).strip().lower(), str(ref).strip().lower()\n",
    "    if p == r: return \"correct\"\n",
    "    if r in [\"yes\",\"no\"] and p in [\"yes\",\"no\"] and p != r: return \"yn_mismatch\"\n",
    "    if any(ch.isdigit() for ch in r) and not any(ch.isdigit() for ch in p): return \"number_missing\"\n",
    "    return \"other\"\n",
    "\n",
    "fa_df = batch_df.copy()\n",
    "fa_df[\"error_type\"] = [error_type(p, r) for p, r in zip(fa_df[\"pred_answer\"], fa_df[\"answer\"])]\n",
    "print(fa_df[\"error_type\"].value_counts())\n",
    "fa_df[fa_df[\"error_type\"]!=\"correct\"][[\"question\",\"answer\",\"pred_answer\",\"error_type\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef21cbf",
   "metadata": {},
   "source": [
    "# Advanced Evaluation using RAGAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e75b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     \"question\": batch_df[\"question\"].astype(str).tolist(),                     # Question\n",
    "#     \"answer\": batch_df[\"pred_answer\"].astype(str).tolist(),                    # Generated Answer\n",
    "#     \"contexts\": [ [ctx] for ctx in batch_df[\"retrieved_id\"].apply(lambda rid: passages_reset.loc[passages_reset[\"id\"]==rid, \"passage\"].values[0] if (passages_reset[\"id\"]==rid).any() else \"\").tolist() ],\n",
    "#     \"ground_truths\": [ [gt] for gt in batch_df[\"answer\"].astype(str).tolist() ], # Reference Answer\n",
    "# }\n",
    "\n",
    "# # Convert dict to dataset\n",
    "# dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dd6546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 11400.04 examples/s]\n",
      "Evaluating:  12%|█▏        | 47/400 [00:12<00:53,  6.66it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  22%|██▏       | 88/400 [00:19<00:53,  5.88it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  24%|██▍       | 95/400 [00:19<00:34,  8.94it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  24%|██▍       | 98/400 [00:19<00:30,  9.82it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  44%|████▍     | 178/400 [00:30<00:24,  9.06it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  70%|███████   | 282/400 [00:45<00:17,  6.84it/s]Failed to parse output. Returning None.\n",
      "Evaluating:  76%|███████▋  | 306/400 [00:48<00:12,  7.40it/s]No statements were generated from the answer.\n",
      "Evaluating: 100%|██████████| 400/400 [01:19<00:00,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ragas_naive.csv with 100 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which property did James Monroe sell in 1817?</td>\n",
       "      <td>Highland Plantation</td>\n",
       "      <td>[Monroe had racked up many debts during his ye...</td>\n",
       "      <td>Monroe Hill on the grounds of the University o...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.901120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Was it a two-sentence description that complet...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>[Immediately after Lee's surrender, Grant had ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.831117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is an otter's den called?</td>\n",
       "      <td>a holt</td>\n",
       "      <td>[An otter's den is called a holt.  Male otters...</td>\n",
       "      <td>Holt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who dismantled partisan and sectional coalitio...</td>\n",
       "      <td>Wilson dismantled partisan and sectional coali...</td>\n",
       "      <td>[The longest section of Congressional Governme...</td>\n",
       "      <td>many congressmen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.910533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did James Monroe fight in the Continental Army?</td>\n",
       "      <td>yes</td>\n",
       "      <td>[* Monroe was (arguably) the last president to...</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0      Which property did James Monroe sell in 1817?   \n",
       "1  Was it a two-sentence description that complet...   \n",
       "2                     What is an otter's den called?   \n",
       "3  Who dismantled partisan and sectional coalitio...   \n",
       "4    Did James Monroe fight in the Continental Army?   \n",
       "\n",
       "                                              answer  \\\n",
       "0                                Highland Plantation   \n",
       "1                                                Yes   \n",
       "2                                             a holt   \n",
       "3  Wilson dismantled partisan and sectional coali...   \n",
       "4                                                yes   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [Monroe had racked up many debts during his ye...   \n",
       "1  [Immediately after Lee's surrender, Grant had ...   \n",
       "2  [An otter's den is called a holt.  Male otters...   \n",
       "3  [The longest section of Congressional Governme...   \n",
       "4  [* Monroe was (arguably) the last president to...   \n",
       "\n",
       "                                        ground_truth  faithfulness  \\\n",
       "0  Monroe Hill on the grounds of the University o...           0.0   \n",
       "1                                                yes           1.0   \n",
       "2                                               Holt           1.0   \n",
       "3                                   many congressmen           0.0   \n",
       "4                                                yes           0.0   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  \n",
       "0          0.901120                0.0             0.0  \n",
       "1          0.831117                1.0             1.0  \n",
       "2          1.000000                1.0             1.0  \n",
       "3          0.910533                0.0             0.0  \n",
       "4          0.957436                1.0             1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # RAGAs single-pass minimal eval — combine 4 metrics with tight budgets\n",
    "# import os, numpy as np\n",
    "# from ragas import evaluate as ragas_evaluate\n",
    "# from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "# from ragas.run_config import RunConfig\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# # adjust here to fit your rate limit\n",
    "# K = min(100, len(dataset[\"question\"]))     # set 30 if you still hit 429\n",
    "# MAX_CHARS = 600                        \n",
    "# MAX_TOKENS = 128                          # set 128 if needed\n",
    "\n",
    "# rng = np.random.default_rng(42)\n",
    "# idx = rng.choice(len(dataset[\"question\"]), size=K, replace=False)\n",
    "# subset = dataset.select(idx.tolist())\n",
    "\n",
    "# def _truncate(row, max_chars=MAX_CHARS):\n",
    "#     ctxs = row.get(\"contexts\", [])\n",
    "#     row[\"contexts\"] = [ctxs[0][:max_chars]] if ctxs else [\"\"]\n",
    "#     return row\n",
    "# subset = subset.map(_truncate)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=MAX_TOKENS, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "# rc = RunConfig(timeout=120)\n",
    "\n",
    "# metrics = [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "# res = ragas_evaluate(subset, metrics=metrics, llm=llm, run_config=rc)\n",
    "# df = res.to_pandas()\n",
    "# df.to_csv(\"ragas_naive.csv\", index=False)\n",
    "# print(f\"Saved ragas_naive.csv with {len(df)} rows\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6620e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Cross-Encoder for reranking\n",
    "from sentence_transformers import CrossEncoder\n",
    "RERANK_MODEL_NAME = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "reranker = CrossEncoder(RERANK_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8043c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced pipeline: mpnet embeddings + CrossEncoder reranking (top-3),\n",
    "# low-budget generation and RAGAs evaluation\n",
    "import os, json, numpy as np, pandas as pd\n",
    "from typing import List, Tuple\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate as ragas_evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from ragas.run_config import RunConfig\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 1) Reranker helper with confidence\n",
    "\n",
    "def rerank_with_confidence(query: str,\n",
    "                           candidate_ids: List[int],\n",
    "                           candidate_texts: List[str]) -> Tuple[List[float], List[float], List[Tuple[int, float]]]:\n",
    "    pairs = [(query, t) for t in candidate_texts]\n",
    "    scores = reranker.predict(pairs).tolist()\n",
    "    # Softmax for normalized confidence over candidates\n",
    "    scores_np = np.array(scores, dtype=float)\n",
    "    exps = np.exp(scores_np - np.max(scores_np))\n",
    "    probs = exps / (exps.sum() if exps.sum() > 0 else 1.0)\n",
    "    id_prob_list = list(zip(candidate_ids, probs.astype(float).tolist()))\n",
    "    return scores, probs.astype(float).tolist(), id_prob_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369f8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E20251003 23:31:54.334995 1871613 milvus_proxy.cpp:210] [SERVER][Search][] Can not find rag_mini_mpnet's schema\n",
      "RPC error: [search], <MilvusException: (code=100, message=Can not find rag_mini_mpnet's schema: collection not found)>, <Time:{'RPC start': '2025-10-03 23:31:54.332555', 'RPC error': '2025-10-03 23:31:54.336750'}>\n",
      "Failed to search collection: rag_mini_mpnet\n"
     ]
    },
    {
     "ename": "MilvusException",
     "evalue": "<MilvusException: (code=100, message=Can not find rag_mini_mpnet's schema: collection not found)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[62], line 19\u001b[0m\n\u001b[1;32m     18\u001b[0m q_emb \u001b[38;5;241m=\u001b[39m embedding_model_mpnet\u001b[38;5;241m.\u001b[39mencode([q], normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m sres \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrag_mini_mpnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_emb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43manns_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCAND_LIMIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m hits_local \u001b[38;5;241m=\u001b[39m sres[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sres) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/milvus_client/milvus_client.py:331\u001b[0m, in \u001b[0;36mMilvusClient.search\u001b[0;34m(self, collection_name, data, filter, limit, output_fields, search_params, timeout, partition_names, anns_field, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to search collection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, collection_name)\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    333\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/milvus_client/milvus_client.py:317\u001b[0m, in \u001b[0;36mMilvusClient.search\u001b[0;34m(self, collection_name, data, filter, limit, output_fields, search_params, timeout, partition_names, anns_field, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43manns_field\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:147\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:143\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:182\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:122\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:87\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:801\u001b[0m, in \u001b[0;36mGrpcHandler.search\u001b[0;34m(self, collection_name, data, anns_field, param, limit, expression, partition_names, output_fields, round_decimal, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m request \u001b[38;5;241m=\u001b[39m Prepare\u001b[38;5;241m.\u001b[39msearch_requests_with_expr(\n\u001b[1;32m    790\u001b[0m     collection_name,\n\u001b[1;32m    791\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    800\u001b[0m )\n\u001b[0;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_decimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mround_decimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:742\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search\u001b[0;34m(self, request, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchFuture(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, e)\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:735\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search\u001b[0;34m(self, request, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stub\u001b[38;5;241m.\u001b[39mSearch(request, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m--> 735\u001b[0m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m round_decimal \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround_decimal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/utils.py:63\u001b[0m, in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status\u001b[38;5;241m.\u001b[39mcode, status\u001b[38;5;241m.\u001b[39mreason, status\u001b[38;5;241m.\u001b[39merror_code)\n",
      "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=100, message=Can not find rag_mini_mpnet's schema: collection not found)>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[62], line 19\u001b[0m\n\u001b[1;32m     18\u001b[0m q_emb \u001b[38;5;241m=\u001b[39m embedding_model_mpnet\u001b[38;5;241m.\u001b[39mencode([q], normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m sres \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrag_mini_mpnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_emb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43manns_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCAND_LIMIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m hits_local \u001b[38;5;241m=\u001b[39m sres[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sres) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/milvus_client/milvus_client.py:331\u001b[0m, in \u001b[0;36mMilvusClient.search\u001b[0;34m(self, collection_name, data, filter, limit, output_fields, search_params, timeout, partition_names, anns_field, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to search collection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, collection_name)\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    333\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/milvus_client/milvus_client.py:317\u001b[0m, in \u001b[0;36mMilvusClient.search\u001b[0;34m(self, collection_name, data, filter, limit, output_fields, search_params, timeout, partition_names, anns_field, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43manns_field\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:147\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:143\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:182\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:122\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:87\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:801\u001b[0m, in \u001b[0;36mGrpcHandler.search\u001b[0;34m(self, collection_name, data, anns_field, param, limit, expression, partition_names, output_fields, round_decimal, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m request \u001b[38;5;241m=\u001b[39m Prepare\u001b[38;5;241m.\u001b[39msearch_requests_with_expr(\n\u001b[1;32m    790\u001b[0m     collection_name,\n\u001b[1;32m    791\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    800\u001b[0m )\n\u001b[0;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_decimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mround_decimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:742\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search\u001b[0;34m(self, request, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchFuture(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, e)\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:735\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search\u001b[0;34m(self, request, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stub\u001b[38;5;241m.\u001b[39mSearch(request, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m--> 735\u001b[0m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m round_decimal \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround_decimal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/utils.py:63\u001b[0m, in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status\u001b[38;5;241m.\u001b[39mcode, status\u001b[38;5;241m.\u001b[39mreason, status\u001b[38;5;241m.\u001b[39merror_code)\n",
      "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=100, message=Can not find rag_mini_mpnet's schema: collection not found)>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMilvusException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m subset_q[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist():\n\u001b[1;32m     18\u001b[0m     q_emb \u001b[38;5;241m=\u001b[39m embedding_model_mpnet\u001b[38;5;241m.\u001b[39mencode([q], normalize_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 19\u001b[0m     sres \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrag_mini_mpnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_emb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43manns_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCAND_LIMIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     hits_local \u001b[38;5;241m=\u001b[39m sres[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sres) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m     27\u001b[0m     cand_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(h[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hits_local]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/milvus_client/milvus_client.py:331\u001b[0m, in \u001b[0;36mMilvusClient.search\u001b[0;34m(self, collection_name, data, filter, limit, output_fields, search_params, timeout, partition_names, anns_field, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    330\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to search collection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, collection_name)\n\u001b[0;32m--> 331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    333\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hits \u001b[38;5;129;01min\u001b[39;00m res:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/milvus_client/milvus_client.py:317\u001b[0m, in \u001b[0;36mMilvusClient.search\u001b[0;34m(self, collection_name, data, filter, limit, output_fields, search_params, timeout, partition_names, anns_field, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43manns_field\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    330\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to search collection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, collection_name)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:147\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[1;32m    146\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minner_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, <Time:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mFutureTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    149\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgRPC timeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:143\u001b[0m, in \u001b[0;36merror_handler.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC start\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MilvusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    145\u001b[0m     record_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRPC error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:182\u001b[0m, in \u001b[0;36mtracing_request.<locals>.wrapper.<locals>.handler\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m req_id:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_onetime_request_id(req_id)\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:122\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m         back_off \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(back_off \u001b[38;5;241m*\u001b[39m back_off_multiplier, max_back_off)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 122\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/decorators.py:87\u001b[0m, in \u001b[0;36mretry_on_rpc_failure.<locals>.wrapper.<locals>.handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;66;03m# Do not retry on these codes\u001b[39;00m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mcode() \u001b[38;5;129;01min\u001b[39;00m IGNORE_RETRY_CODES:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:801\u001b[0m, in \u001b[0;36mGrpcHandler.search\u001b[0;34m(self, collection_name, data, anns_field, param, limit, expression, partition_names, output_fields, round_decimal, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m check_pass_param(\n\u001b[1;32m    779\u001b[0m     limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[1;32m    780\u001b[0m     round_decimal\u001b[38;5;241m=\u001b[39mround_decimal,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    786\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    787\u001b[0m )\n\u001b[1;32m    789\u001b[0m request \u001b[38;5;241m=\u001b[39m Prepare\u001b[38;5;241m.\u001b[39msearch_requests_with_expr(\n\u001b[1;32m    790\u001b[0m     collection_name,\n\u001b[1;32m    791\u001b[0m     data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    800\u001b[0m )\n\u001b[0;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_decimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mround_decimal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:742\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search\u001b[0;34m(self, request, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_async\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchFuture(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, e)\n\u001b[0;32m--> 742\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/grpc_handler.py:735\u001b[0m, in \u001b[0;36mGrpcHandler._execute_search\u001b[0;34m(self, request, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SearchFuture(future, func)\n\u001b[1;32m    734\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stub\u001b[38;5;241m.\u001b[39mSearch(request, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m--> 735\u001b[0m \u001b[43mcheck_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m round_decimal \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mround_decimal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SearchResult(response\u001b[38;5;241m.\u001b[39mresults, round_decimal, status\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pymilvus/client/utils.py:63\u001b[0m, in \u001b[0;36mcheck_status\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcheck_status\u001b[39m(status: Status):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m status\u001b[38;5;241m.\u001b[39merror_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MilvusException(status\u001b[38;5;241m.\u001b[39mcode, status\u001b[38;5;241m.\u001b[39mreason, status\u001b[38;5;241m.\u001b[39merror_code)\n",
      "\u001b[0;31mMilvusException\u001b[0m: <MilvusException: (code=100, message=Can not find rag_mini_mpnet's schema: collection not found)>"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Build enhanced answers on a modest subset to keep runtime small\n",
    "TOP_K = 1\n",
    "CAND_LIMIT = 30\n",
    "MAX_NEW_TOKENS = 24\n",
    "SAMPLE_N = min(100, len(clean_queries))  # meets the >=100 guideline, runs fast\n",
    "\n",
    "# Ensure mpnet model is available (created earlier); fallback if needed\n",
    "try:\n",
    "    embedding_model_mpnet  # type: ignore  # noqa: F821\n",
    "except Exception:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    embedding_model_mpnet = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "pred_answers_enh, contexts_list_enh, confidences = [], [], []\n",
    "subset_q = clean_queries.head(SAMPLE_N).copy()\n",
    "\n",
    "for q in subset_q[\"question\"].astype(str).tolist():\n",
    "    q_emb = embedding_model_mpnet.encode([q], normalize_embeddings=True)\n",
    "    sres = client.search(\n",
    "        collection_name=\"rag_mini_mpnet\",\n",
    "        data=q_emb.tolist(),\n",
    "        anns_field=\"embedding\",\n",
    "        limit=CAND_LIMIT,\n",
    "        search_params={\"metric_type\": \"IP\"}\n",
    "    )\n",
    "    hits_local = sres[0] if len(sres) > 0 else []\n",
    "    cand_ids = [int(h[\"id\"]) for h in hits_local]\n",
    "    cand_texts = [\n",
    "        passages_reset.loc[passages_reset[\"id\"] == cid, \"passage\"].values[0]\n",
    "        for cid in cand_ids\n",
    "    ] if len(cand_ids) > 0 else []\n",
    "\n",
    "    if len(cand_ids) == 0:\n",
    "        contexts = [\"\"]\n",
    "        conf_score = 0.0\n",
    "    else:\n",
    "        _, _, id_prob_list = rerank_with_confidence(q, cand_ids, cand_texts)\n",
    "        sorted_by_prob = sorted(id_prob_list, key=lambda x: x[1], reverse=True)\n",
    "        topk_ids = [cid for cid, _ in sorted_by_prob[:TOP_K]]\n",
    "        contexts = [\n",
    "            passages_reset.loc[passages_reset[\"id\"] == cid, \"passage\"].values[0]\n",
    "            for cid in topk_ids\n",
    "        ]\n",
    "        conf_score = float(np.mean([p for _, p in sorted_by_prob[:TOP_K]])) if len(sorted_by_prob) > 0 else 0.0\n",
    "\n",
    "    ctx_text = \"\\n\\n\".join(contexts)\n",
    "    sys_prompt = \"You are a helpful assistant. Answer concisely using the provided context. If unknown, say you don't know.\"\n",
    "    prompt_i = f\"{sys_prompt}\\nContext: {ctx_text}\\nQuestion: {q}\"\n",
    "    pred_answers_enh.append(generate_answer(prompt_i, max_new_tokens=MAX_NEW_TOKENS))\n",
    "    contexts_list_enh.append(contexts)\n",
    "    confidences.append(conf_score)\n",
    "\n",
    "enhanced_df = subset_q[[\"question\", \"answer\"]].copy()\n",
    "enhanced_df[\"pred_answer\"] = pred_answers_enh\n",
    "enhanced_df[\"contexts_list\"] = contexts_list_enh\n",
    "enhanced_df[\"confidence\"] = confidences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63233001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) EM/F1 on enhanced subset\n",
    "try:\n",
    "    preds_ = enhanced_df[\"pred_answer\"].astype(str).tolist()\n",
    "    refs_ = enhanced_df[\"answer\"].astype(str).tolist()\n",
    "    em_enh = sum(exact_match_score(p, r) for p, r in zip(preds_, refs_)) / len(refs_) * 100.0\n",
    "    f1_enh = sum(f1_score(p, r) for p, r in zip(preds_, refs_)) / len(refs_) * 100.0\n",
    "except Exception:\n",
    "    # Fallback in case helper functions are not in scope\n",
    "    import re, string\n",
    "    def _normalize_answer(s: str) -> str:\n",
    "        def remove_articles(text): return re.sub(r\"\\b(a|an|the)\\b\", \" \", text, flags=re.IGNORECASE)\n",
    "        def remove_punc(text): return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        def white_space_fix(text): return \" \".join(text.split())\n",
    "        return white_space_fix(remove_articles(remove_punc(s.lower())))\n",
    "    def _em(a, b): return int(_normalize_answer(a) == _normalize_answer(b))\n",
    "    def _f1(a, b):\n",
    "        p = _normalize_answer(a).split(); t = _normalize_answer(b).split()\n",
    "        if not p and not t: return 100.0\n",
    "        if not p or not t: return 0.0\n",
    "        overlap = 0\n",
    "        for tok in set(p): overlap += min(p.count(tok), t.count(tok))\n",
    "        if overlap == 0: return 0.0\n",
    "        precision = overlap / len(p); recall = overlap / len(t)\n",
    "        return 2 * precision * recall / (precision + recall) * 100.0\n",
    "    em_enh = sum(_em(p, r) for p, r in zip(preds_, refs_)) / len(refs_) * 100.0\n",
    "    f1_enh = sum(_f1(p, r) for p, r in zip(preds_, refs_)) / len(refs_)\n",
    "\n",
    "with open(\"enhanced_results.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"embedding_model\": \"sentence-transformers/all-mpnet-base-v2\",\n",
    "        \"reranker\": RERANK_MODEL_NAME,\n",
    "        \"top_k\": TOP_K,\n",
    "        \"num_eval\": int(len(enhanced_df)),\n",
    "        \"em\": float(em_enh),\n",
    "        \"f1\": float(f1_enh)\n",
    "    }, f, indent=2)\n",
    "print({\"enhanced_subset\": len(enhanced_df), \"em\": em_enh, \"f1\": f1_enh})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac729a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Low-budget RAGAs for enhanced\n",
    "K = min(60, len(enhanced_df))  # smaller than naive to avoid rate limits\n",
    "if \"OPENAI_API_KEY\" in os.environ and os.environ[\"OPENAI_API_KEY\"]:\n",
    "    data_enh = {\n",
    "        \"question\": enhanced_df[\"question\"].astype(str).tolist(),\n",
    "        \"answer\": enhanced_df[\"pred_answer\"].astype(str).tolist(),\n",
    "        \"contexts\": enhanced_df[\"contexts_list\"].tolist(),\n",
    "        \"ground_truth\": enhanced_df[\"answer\"].astype(str).tolist(),\n",
    "    }\n",
    "    ds_enh = Dataset.from_dict(data_enh)\n",
    "    rng = np.random.default_rng(123)\n",
    "    idx = rng.choice(len(ds_enh), size=K, replace=False)\n",
    "    subset_enh = ds_enh.select(idx.tolist())\n",
    "\n",
    "    def _trim(row, max_chars=600):\n",
    "        row[\"contexts\"] = [c[:max_chars] for c in row.get(\"contexts\", [])]\n",
    "        return row\n",
    "    subset_enh = subset_enh.map(_trim)\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=96, api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    rc = RunConfig(timeout=120)\n",
    "    metrics = [faithfulness, answer_relevancy, context_precision, context_recall]\n",
    "\n",
    "    res = ragas_evaluate(subset_enh, metrics=metrics, llm=llm, run_config=rc)\n",
    "    df_enh = res.to_pandas()\n",
    "    df_enh.to_csv(\"ragas_enhanced.csv\", index=False)\n",
    "    print(f\"Saved ragas_enhanced.csv with {len(df_enh)} rows\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY not set; skipping RAGAs for enhanced.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda2f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results summary — compare naive vs enhanced (saved to current directory)\n",
    "import pandas as pd, numpy as np, json, os\n",
    "\n",
    "naive = pd.read_csv(\"ragas_naive.csv\")\n",
    "enh   = pd.read_csv(\"ragas_enhanced.csv\") if os.path.exists(\"ragas_enhanced.csv\") else pd.DataFrame()\n",
    "cols = [\"faithfulness\",\"answer_relevancy\",\"context_precision\",\"context_recall\"]\n",
    "\n",
    "def means(df):\n",
    "    return {c: float(np.nanmean(df[c])) for c in cols if c in df.columns and len(df) > 0}\n",
    "\n",
    "naive_mean = means(naive)\n",
    "enh_mean   = means(enh)\n",
    "\n",
    "cmp = pd.DataFrame([\n",
    "    {\"metric\": c, \"naive\": naive_mean.get(c), \"enhanced\": enh_mean.get(c),\n",
    "     \"delta\": (enh_mean.get(c, np.nan) - naive_mean.get(c, np.nan)) if enh_mean.get(c) is not None else None}\n",
    "    for c in cols\n",
    "])\n",
    "\n",
    "cmp.to_csv(\"comparison_analysis.csv\", index=False)\n",
    "with open(\"enhanced_results_summary.json\",\"w\") as f:\n",
    "    json.dump({\"naive\": naive_mean, \"enhanced\": enh_mean,\n",
    "               \"delta\": {r[\"metric\"]: r[\"delta\"] for _, r in cmp.iterrows()}}, f, indent=2)\n",
    "\n",
    "print(\"Saved comparison_analysis.csv and enhanced_results_summary.json\")\n",
    "cmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598891d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Parameter comparison (2 embeddings × top_k 3/5/10) with EM/F1\n",
    "from sentence_transformers import SentenceTransformer as ST\n",
    "import pandas as pd\n",
    "\n",
    "EMBED_MODELS = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\",  # 384\n",
    "    \"sentence-transformers/all-mpnet-base-v2\", # 768\n",
    "]\n",
    "COLLECTION_BY_MODEL = {\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\": \"rag_mini\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\": \"rag_mini_mpnet\",\n",
    "}\n",
    "TOP_KS = [3, 5]\n",
    "CAND_LIMIT = 30\n",
    "MAX_NEW_TOKENS = 24\n",
    "\n",
    "subset_for_grid = clean_queries.head(120).copy()  # keep it light but >=100\n",
    "\n",
    "results_rows = []\n",
    "for model_name in EMBED_MODELS:\n",
    "    emb_model = ST(model_name)\n",
    "    collection = COLLECTION_BY_MODEL[model_name]\n",
    "    for q in subset_for_grid[\"question\"].astype(str).tolist():\n",
    "        q_emb = emb_model.encode([q], normalize_embeddings=True)\n",
    "        sres = client.search(\n",
    "            collection_name=collection,\n",
    "            data=q_emb.tolist(),\n",
    "            anns_field=\"embedding\",\n",
    "            limit=CAND_LIMIT,\n",
    "            search_params={\"metric_type\": \"IP\"}\n",
    "        )\n",
    "        hits_local = sres[0] if len(sres) > 0 else []\n",
    "        cand_ids = [int(h[\"id\"]) for h in hits_local]\n",
    "        cand_texts = [\n",
    "            passages_reset.loc[passages_reset[\"id\"]==cid, \"passage\"].values[0]\n",
    "            for cid in cand_ids\n",
    "        ] if len(cand_ids) > 0 else []\n",
    "\n",
    "        # simple rerank to stabilize order across top_k\n",
    "        if len(cand_ids) > 0:\n",
    "            _, _, id_prob_list = rerank_with_confidence(q, cand_ids, cand_texts)\n",
    "            sorted_ids = [cid for cid,_ in sorted(id_prob_list, key=lambda x:x[1], reverse=True)]\n",
    "        else:\n",
    "            sorted_ids = []\n",
    "\n",
    "        for k in TOP_KS:\n",
    "            topk_ids = sorted_ids[:k]\n",
    "            ctxs = [passages_reset.loc[passages_reset[\"id\"]==cid, \"passage\"].values[0] for cid in topk_ids] if len(topk_ids)>0 else [\"\"]\n",
    "            ctx_text = \"\\n\\n\".join(ctxs)\n",
    "            sys_prompt = \"You are a helpful assistant. Answer concisely using the provided context. If unknown, say you don't know.\"\n",
    "            prompt_i = f\"{sys_prompt}\\nContext: {ctx_text}\\nQuestion: {q}\"\n",
    "            pred = generate_answer(prompt_i, max_new_tokens=MAX_NEW_TOKENS)\n",
    "            results_rows.append({\n",
    "                \"embedding_model\": model_name,\n",
    "                \"top_k\": k,\n",
    "                \"question\": q,\n",
    "                \"pred\": pred,\n",
    "            })\n",
    "\n",
    "# assemble and score\n",
    "res_df = pd.DataFrame(results_rows)\n",
    "merged = subset_for_grid[[\"question\",\"answer\"]].merge(res_df, on=\"question\", how=\"right\")\n",
    "\n",
    "scores = []\n",
    "for (m, k), g in merged.groupby([\"embedding_model\",\"top_k\"]):\n",
    "    preds = g[\"pred\"].astype(str).tolist()\n",
    "    refs = g[\"answer\"].astype(str).tolist()\n",
    "    em_ = sum(exact_match_score(p, r) for p, r in zip(preds, refs)) / len(refs) * 100.0\n",
    "    f1_ = sum(f1_score(p, r) for p, r in zip(preds, refs)) / len(refs) * 100.0\n",
    "    scores.append({\"embedding_model\": m, \"top_k\": k, \"em\": em_, \"f1\": f1_})\n",
    "\n",
    "param_cmp = pd.DataFrame(scores).sort_values([\"embedding_model\",\"top_k\"]).reset_index(drop=True)\n",
    "param_cmp.to_csv(\"parameter_comparison.csv\", index=False)\n",
    "print(\"Saved parameter_comparison.csv\")\n",
    "param_cmp.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
